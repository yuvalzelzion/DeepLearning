{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoHTQQEvGdG"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPnUSKoSu5yi"
      },
      "source": [
        "## Install the latest version of TorchText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KixLL8Tgtp9F",
        "outputId": "d8c46800-2002-46b9-f3d5-bd586a742f2f"
      },
      "source": [
        "! pip install torchtext==0.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnj8VG2ssnK8"
      },
      "source": [
        "## Import all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30lZU3fksO7Q"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9WHElEsuni"
      },
      "source": [
        "## Define the ngrams and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muvG1QNytYKQ"
      },
      "source": [
        "NGRAMS = 2\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6r1YY63u3LG"
      },
      "source": [
        "# Get the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdG7rr8ita3Y"
      },
      "source": [
        "## Read the DBpedia dataset that is provided by the TorchText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cjvMVvntcUQ",
        "outputId": "39d48447-ae3e-444e-a1c1-788c4c12bd4f"
      },
      "source": [
        "if not os.path.isdir('./.data'):\n",
        "    os.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['DBpedia'](\n",
        "    root='./.data', ngrams=NGRAMS, vocab=None)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dbpedia_csv.tar.gz: 68.3MB [00:01, 48.5MB/s]\n",
            "560000lines [00:58, 9540.03lines/s]\n",
            "560000lines [01:53, 4927.54lines/s]\n",
            "70000lines [00:14, 4930.08lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqaPFvNNuvxQ"
      },
      "source": [
        "## Verify the length and the number of labels of the downloaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbbZlnHcuxH4",
        "outputId": "5e5c3f68-ab24-4748-dd2c-3200e2fc2d90"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "print(len(train_dataset.get_labels()))\n",
        "print(len(test_dataset.get_labels()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "560000\n",
            "70000\n",
            "14\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ge7HIDvi1O"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7qy_A7Svwjo"
      },
      "source": [
        "## Use the CUDA architecture to speed-up the runtime and execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV76zQUHvvgp",
        "outputId": "e83e70d4-346d-4ec9-b6c3-8b382fb9de28"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewimjKRhvmrg"
      },
      "source": [
        "## Define the model for the classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Uq_3DjvoRA"
      },
      "source": [
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u27M7nKwiDf"
      },
      "source": [
        "## Initialize the hyperparameters and define the function to generate the training batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzaC3SujwSqL",
        "outputId": "713d0d41-efe7-49a3-8b68-07839c99ba45"
      },
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
        "EMBED_DIM = 32\n",
        "NUN_CLASS = len(train_dataset.get_labels())\n",
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)\n",
        "\n",
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label\n",
        "\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextSentiment(\n",
            "  (embedding): EmbeddingBag(6375026, 32, mode=mean)\n",
            "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqGxHMcqwmv_"
      },
      "source": [
        "## Define the function to train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDmIVKXEwnwJ"
      },
      "source": [
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IbnphLZwtew"
      },
      "source": [
        "## Train the model in 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uBfWmp-wu_O",
        "outputId": "97b1b2aa-f697-42e1-b3c6-f862f9886570"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 56 seconds\n",
            "\tLoss: 0.0084(train)\t|\tAcc: 96.2%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 97.9%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 56 seconds\n",
            "\tLoss: 0.0024(train)\t|\tAcc: 99.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.1%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 56 seconds\n",
            "\tLoss: 0.0012(train)\t|\tAcc: 99.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.2%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 56 seconds\n",
            "\tLoss: 0.0006(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.2%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 56 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.3%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjPFDcoxT1H"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbuCmrdgxVMu"
      },
      "source": [
        "## Test the model on individual text strings and predict the class label for that text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL41RGOlxg44"
      },
      "source": [
        "DBpedia_label = {0: 'Company',\n",
        "                1: 'EducationalInstitution',\n",
        "                2: 'Artist',\n",
        "                3: 'Athlete',\n",
        "                4: 'OfficeHolder',\n",
        "                5: 'MeanOfTransportation',\n",
        "                6: 'Building',\n",
        "                7: 'NaturalPlace',\n",
        "                8: 'Village',\n",
        "                9: 'Animal',\n",
        "                10: 'Plant',\n",
        "                11: 'Album',\n",
        "                12: 'Film',\n",
        "                13: 'WrittenWork'}\n",
        "\n",
        "def predict(text, model, vocab, ngrams):\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor([vocab[token]\n",
        "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4DmPk2aydiG"
      },
      "source": [
        "## First prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9M5AAoiyfun",
        "outputId": "da136f4e-8649-4c86-8381-c6efabea98b0"
      },
      "source": [
        "ex_text_str = \"Brekke Church (Norwegian: Brekke kyrkje) is a parish church in Gulen Municipality in Sogn og Fjordane county, Norway. It is located in the village of Brekke. The church is part of the Brekke parish in the Nordhordland deanery in the Diocese of BjÃ¸rgvin. The white, wooden church, which has 390 seats, was consecrated on 19 November 1862 by the local Dean Thomas Erichsen. The architect Christian Henrik Grosch made the designs for the church, which is the third church on the site.\"\n",
        "\n",
        "print(\"This is a %s news\" %DBpedia_label[predict(ex_text_str, model, vocab, 2)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a NaturalPlace news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRzgy5rUyk-R"
      },
      "source": [
        "## Second Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjVTFO_Oylw7",
        "outputId": "98215492-96b7-4be6-9c10-c1d50605e79d"
      },
      "source": [
        "ex_text_str2 = \"Cerithiella superba is a species of very small sea snail, a marine gastropod mollusk in the family Newtoniellidae. This species is known from European waters. It was described by Thiele, 1912.\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str2, model, vocab, 2)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Plant class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYP0q6J6ynJu"
      },
      "source": [
        "## Third Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSZAMR0SypG_",
        "outputId": "d36a9910-ca01-41c3-c373-8f86a1f72b95"
      },
      "source": [
        "ex_text_str3 = \"Nithari is a village in the western part of the state of Uttar Pradesh India bordering on New Delhi. Nithari forms part of the New Okhla Industrial Development Authority's planned industrial city Noida falling in Sector 31. Nithari made international news headlines in December 2006 when the skeletons of a number of apparently murdered women and children were unearthed in the village.\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str3, model, vocab, 2)])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Animal class\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}